{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XxQrumWwh-zd"
      ],
      "mount_file_id": "1-pCmhERM0Njp9ECKKI8DfJCxmK7eCQMR",
      "authorship_tag": "ABX9TyNMliwNmAwosyltYao2oqKv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Log-Yair/Endymion/blob/src/data_handler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lola"
      ],
      "metadata": {
        "id": "fimkU58nZpnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports**"
      ],
      "metadata": {
        "id": "ap4CO7ciTI89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import math\n",
        "import hashlib\n",
        "import urllib.request\n",
        "from dataclasses import dataclass, asdict\n",
        "from pathlib import Path\n",
        "from typing import Dict, Optional, Tuple, List, Any\n",
        "\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "w38iydlDXB6I"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Handling"
      ],
      "metadata": {
        "id": "VMS9yKNCTRD8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "V2ebS1B62N8J"
      },
      "outputs": [],
      "source": [
        "\n",
        "'''\n",
        "-------------------\n",
        "Data structures\n",
        "-------------------\n",
        "'''\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class LOLATileSpec:\n",
        "    \"\"\"\n",
        "    Identifies a LOLA polar float_img tile by its base filename (without extension).\n",
        "    Example: 'ldem_85s_20m_float'\n",
        "    \"\"\"\n",
        "    tile_id: str\n",
        "    img_url: str\n",
        "    lbl_url: str\n",
        "\n",
        "    def filenames(self) -> Tuple[str, str]:\n",
        "        return f\"{self.tile_id}.img\", f\"{self.tile_id}.lbl\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class PDSImageMeta:\n",
        "    \"\"\"\n",
        "    Minimal metadata parsed from a PDS3 .LBL label file.\n",
        "    Keep it flexible; add fields as you discover them in your labels.\n",
        "\n",
        "    NOTE:\n",
        "    This parser/meta is specialised for LOLA polar float_img PDS3 labels.\n",
        "    It is NOT a general-purpose PDS3 parser.\n",
        "    \"\"\"\n",
        "    record_bytes: Optional[int] = None\n",
        "    file_records: Optional[int] = None\n",
        "\n",
        "    lines: Optional[int] = None\n",
        "    line_samples: Optional[int] = None\n",
        "    sample_type: Optional[str] = None\n",
        "    sample_bits: Optional[int] = None\n",
        "\n",
        "    unit: Optional[str] = None\n",
        "    offset: Optional[float] = None\n",
        "    scaling_factor: Optional[float] = None\n",
        "    missing_constant: Optional[float] = None\n",
        "\n",
        "    # keep raw label for debugging / provenance\n",
        "    raw: Optional[Dict[str, Any]] = None\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class RasterTile:\n",
        "    \"\"\"\n",
        "    A tile of raster data plus meta.\n",
        "    For production we use numpy.memmap so we don't load the full 15168x15168 tile into RAM.\n",
        "    \"\"\"\n",
        "    tile_id: str\n",
        "    data: np.ndarray  # can be np.memmap\n",
        "    meta: PDSImageMeta\n",
        "\n",
        "\n",
        "'''\n",
        "----------------------------\n",
        "Data handler\n",
        "----------------------------\n",
        "'''\n",
        "\n",
        "class DataHandler:\n",
        "    \"\"\"\n",
        "    Endymion - DataHandler\n",
        "\n",
        "    Responsibility:\n",
        "      - Download/caching of PDS .IMG/.LBL\n",
        "      - Parse labels (PDS3-ish) to interpret .IMG binary\n",
        "      - Load raster data (prefer memmap)\n",
        "      - Provide ROI extraction hooks for FeatureExtractor / Hazard pipeline\n",
        "\n",
        "    Notes:\n",
        "      - Keep this module \"dumb and reliable\":\n",
        "        no slope/roughness here (that belongs in FeatureExtractor).\n",
        "      - Unit conversion (km->m) and offset usage belong in standardisation.\n",
        "    \"\"\"\n",
        "\n",
        "    # Basic KEY = VALUE matcher for common PDS3 label lines\n",
        "    _kv_re = re.compile(r\"^\\s*([A-Z0-9_\\-^]+)\\s*=\\s*(.+?)\\s*$\")\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        cache_dir: str | Path = \"/content/endymion_cache/lola\",\n",
        "        user_agent: str = \"Endymion-DataHandler/0.1\",\n",
        "        timeout_sec: int = 60,\n",
        "    ) -> None:\n",
        "        self.cache_dir = Path(cache_dir)\n",
        "        self.cache_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        self.user_agent = user_agent\n",
        "        self.timeout_sec = timeout_sec\n",
        "\n",
        "        # Simple in-memory registry (you can persist this later)\n",
        "        self.tiles: Dict[str, LOLATileSpec] = {}\n",
        "\n",
        "    '''\n",
        "    ----------------------------\n",
        "     Registration\n",
        "    ----------------------------\n",
        "    '''\n",
        "\n",
        "    def register_tile(self, spec: LOLATileSpec) -> None:\n",
        "        self.tiles[spec.tile_id] = spec\n",
        "\n",
        "    def register_tiles(self, specs: List[LOLATileSpec]) -> None:\n",
        "        for s in specs:\n",
        "            self.register_tile(s)\n",
        "\n",
        "    '''\n",
        "    ----------------------------\n",
        "     Download & caching\n",
        "    ----------------------------\n",
        "    '''\n",
        "\n",
        "    def _local_paths(self, tile_id: str) -> Tuple[Path, Path]:\n",
        "        img_path = self.cache_dir / f\"{tile_id}.img\"\n",
        "        lbl_path = self.cache_dir / f\"{tile_id}.lbl\"\n",
        "        return img_path, lbl_path\n",
        "\n",
        "    def _download_file(self, url: str, out_path: Path) -> None:\n",
        "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        req = urllib.request.Request(\n",
        "            url,\n",
        "            headers={\"User-Agent\": self.user_agent},\n",
        "            method=\"GET\",\n",
        "        )\n",
        "        with urllib.request.urlopen(req, timeout=self.timeout_sec) as resp:\n",
        "            data = resp.read()\n",
        "\n",
        "        # atomic write\n",
        "        tmp = out_path.with_suffix(out_path.suffix + \".part\")\n",
        "        tmp.write_bytes(data)\n",
        "        tmp.replace(out_path)\n",
        "\n",
        "    def ensure_downloaded(self, tile_id: str, force: bool = False) -> Tuple[Path, Path]:\n",
        "        if tile_id not in self.tiles:\n",
        "            raise KeyError(f\"Tile '{tile_id}' is not registered.\")\n",
        "\n",
        "        spec = self.tiles[tile_id]\n",
        "        img_path, lbl_path = self._local_paths(tile_id)\n",
        "\n",
        "        if force or not lbl_path.exists():\n",
        "            self._download_file(spec.lbl_url, lbl_path)\n",
        "\n",
        "        if force or not img_path.exists():\n",
        "            self._download_file(spec.img_url, img_path)\n",
        "\n",
        "        return img_path, lbl_path\n",
        "\n",
        "    '''\n",
        "    ----------------------------\n",
        "     Label parsing (PDS3-ish)\n",
        "    ----------------------------\n",
        "    '''\n",
        "\n",
        "    def parse_lbl(self, lbl_path: str | Path) -> PDSImageMeta:\n",
        "        \"\"\"\n",
        "        Parses a basic PDS3 label into a dict and extracts common keys.\n",
        "        Handles nested object keys like: UNCOMPRESSED_FILE.IMAGE.LINES\n",
        "        \"\"\"\n",
        "        lbl_path = Path(lbl_path)\n",
        "        label_lines = lbl_path.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines()\n",
        "\n",
        "        raw: Dict[str, Any] = {}\n",
        "        current_object_stack: List[str] = []\n",
        "\n",
        "        def set_key(key: str, value: str) -> None:\n",
        "            # Store \"OBJECT.SUBKEY\" namespace when inside OBJECT blocks\n",
        "            if current_object_stack:\n",
        "                raw[\".\".join(current_object_stack + [key])] = value\n",
        "            else:\n",
        "                raw[key] = value\n",
        "\n",
        "        for line in label_lines:\n",
        "            line = line.strip()\n",
        "            if not line or line.startswith(\"/*\"):\n",
        "                continue\n",
        "\n",
        "            # OBJECT / END_OBJECT handling\n",
        "            if line.startswith(\"OBJECT\"):\n",
        "                m = self._kv_re.match(line)\n",
        "                if m:\n",
        "                    obj_name = m.group(2).strip().strip('\"')\n",
        "                    current_object_stack.append(obj_name)\n",
        "                continue\n",
        "\n",
        "            if line.startswith(\"END_OBJECT\"):\n",
        "                if current_object_stack:\n",
        "                    current_object_stack.pop()\n",
        "                continue\n",
        "\n",
        "            m = self._kv_re.match(line)\n",
        "            if m:\n",
        "                k, v = m.group(1), m.group(2)\n",
        "                set_key(k, v)\n",
        "\n",
        "        def pick_any(*keys: str) -> Optional[str]:\n",
        "            \"\"\"\n",
        "            Try exact matches first, then suffix matches.\n",
        "            Suffix matching solves nested forms like UNCOMPRESSED_FILE.IMAGE.LINES.\n",
        "            \"\"\"\n",
        "            for k in keys:\n",
        "                if k in raw:\n",
        "                    return str(raw[k])\n",
        "\n",
        "            suffixes = [f\".{k.split('.')[-1]}\" for k in keys]\n",
        "            for suf in suffixes:\n",
        "                # prefer keys containing \".IMAGE.\"\n",
        "                for kk, vv in raw.items():\n",
        "                    if kk.endswith(suf) and \".IMAGE.\" in f\".{kk}.\":\n",
        "                        return str(vv)\n",
        "                # otherwise accept any suffix match\n",
        "                for kk, vv in raw.items():\n",
        "                    if kk.endswith(suf):\n",
        "                        return str(vv)\n",
        "            return None\n",
        "\n",
        "        def to_int(x: Optional[str]) -> Optional[int]:\n",
        "            if x is None:\n",
        "                return None\n",
        "            try:\n",
        "                return int(x.strip().strip('\"'))\n",
        "            except ValueError:\n",
        "                return None\n",
        "\n",
        "        def to_float(x: Optional[str]) -> Optional[float]:\n",
        "            if x is None:\n",
        "                return None\n",
        "            try:\n",
        "                return float(x.strip().strip('\"'))\n",
        "            except ValueError:\n",
        "                return None\n",
        "\n",
        "        def to_str(x: Optional[str]) -> Optional[str]:\n",
        "            if x is None:\n",
        "                return None\n",
        "            return x.strip().strip('\"')\n",
        "\n",
        "        meta = PDSImageMeta(\n",
        "            record_bytes=to_int(pick_any(\"RECORD_BYTES\")),\n",
        "            file_records=to_int(pick_any(\"FILE_RECORDS\")),\n",
        "\n",
        "            lines=to_int(pick_any(\"IMAGE.LINES\", \"LINES\")),\n",
        "            line_samples=to_int(pick_any(\"IMAGE.LINE_SAMPLES\", \"LINE_SAMPLES\")),\n",
        "            sample_type=to_str(pick_any(\"IMAGE.SAMPLE_TYPE\", \"SAMPLE_TYPE\")),\n",
        "            sample_bits=to_int(pick_any(\"IMAGE.SAMPLE_BITS\", \"SAMPLE_BITS\")),\n",
        "\n",
        "            unit=to_str(pick_any(\"IMAGE.UNIT\", \"UNIT\")),\n",
        "            scaling_factor=to_float(pick_any(\"IMAGE.SCALING_FACTOR\", \"SCALING_FACTOR\")),\n",
        "            offset=to_float(pick_any(\"IMAGE.OFFSET\", \"OFFSET\")),\n",
        "            missing_constant=to_float(pick_any(\"IMAGE.MISSING_CONSTANT\", \"MISSING_CONSTANT\")),\n",
        "\n",
        "            raw=raw,\n",
        "        )\n",
        "        return meta\n",
        "\n",
        "    '''\n",
        "    ----------------------------\n",
        "    IMG loading (float)\n",
        "    ----------------------------\n",
        "    '''\n",
        "\n",
        "    def _numpy_dtype_from_sample_type(self, sample_type: str, sample_bits: int) -> np.dtype:\n",
        "        \"\"\"\n",
        "        Maps PDS SAMPLE_TYPE/SAMPLE_BITS to numpy dtype.\n",
        "        For LOLA float_img tiles: SAMPLE_TYPE=PC_REAL, SAMPLE_BITS=32 (little-endian float32).\n",
        "        \"\"\"\n",
        "        st = (sample_type or \"\").upper()\n",
        "\n",
        "        if \"REAL\" in st or \"FLOAT\" in st:\n",
        "            if sample_bits == 32:\n",
        "                if \"PC\" in st or \"LSB\" in st:\n",
        "                    return np.dtype(\"<f4\")\n",
        "                if \"MSB\" in st:\n",
        "                    return np.dtype(\">f4\")\n",
        "                return np.dtype(\"f4\")\n",
        "            if sample_bits == 64:\n",
        "                if \"PC\" in st or \"LSB\" in st:\n",
        "                    return np.dtype(\"<f8\")\n",
        "                if \"MSB\" in st:\n",
        "                    return np.dtype(\">f8\")\n",
        "                return np.dtype(\"f8\")\n",
        "\n",
        "        raise ValueError(f\"Unsupported SAMPLE_TYPE/SAMPLE_BITS: {sample_type}/{sample_bits}\")\n",
        "\n",
        "    def load_tile(self, tile_id: str, force_download: bool = False, verbose: bool = False) -> RasterTile:\n",
        "        \"\"\"\n",
        "        Ensures files are present, parses label, and returns a memmap-backed RasterTile.\n",
        "        \"\"\"\n",
        "        img_path, lbl_path = self.ensure_downloaded(tile_id, force=force_download)\n",
        "        meta = self.parse_lbl(lbl_path)\n",
        "\n",
        "        # Validate required fields\n",
        "        if meta.lines is None or meta.line_samples is None:\n",
        "            raise ValueError(f\"LBL missing LINES/LINE_SAMPLES for tile '{tile_id}'.\")\n",
        "        if meta.sample_type is None or meta.sample_bits is None:\n",
        "            raise ValueError(f\"LBL missing SAMPLE_TYPE/SAMPLE_BITS for tile '{tile_id}'.\")\n",
        "\n",
        "        dtype = self._numpy_dtype_from_sample_type(meta.sample_type, meta.sample_bits)\n",
        "\n",
        "        # File-size validation (more meaningful than memmap.size checks)\n",
        "        expected_bytes = meta.lines * meta.line_samples * (meta.sample_bits // 8)\n",
        "        actual_bytes = img_path.stat().st_size\n",
        "        if actual_bytes < expected_bytes:\n",
        "            raise IOError(\n",
        "                f\"IMG too small for expected raster: {actual_bytes} bytes < {expected_bytes} bytes \"\n",
        "                f\"for tile '{tile_id}'.\"\n",
        "            )\n",
        "\n",
        "        if verbose:\n",
        "            print(meta.lines, meta.line_samples, meta.sample_type, meta.sample_bits)\n",
        "            if meta.raw:\n",
        "                print([k for k in meta.raw.keys() if k.endswith(\".LINES\") or k.endswith(\".LINE_SAMPLES\")])\n",
        "\n",
        "        # Use memmap so we don't load the full tile into RAM\n",
        "        arr = np.memmap(img_path, dtype=dtype, mode=\"r\", shape=(meta.lines, meta.line_samples))\n",
        "\n",
        "        # Apply missing constant if present (turn into NaN)\n",
        "        # NOTE: This creates a float32 view/copy; do this only if needed.\n",
        "        if meta.missing_constant is not None:\n",
        "            arr = np.array(arr, dtype=np.float32, copy=True)\n",
        "            arr[arr == meta.missing_constant] = np.nan\n",
        "\n",
        "        # Apply scaling factor if present (DN -> HEIGHT in label units)\n",
        "        if meta.scaling_factor is not None:\n",
        "            arr = arr * float(meta.scaling_factor)\n",
        "\n",
        "        return RasterTile(tile_id=tile_id, data=arr, meta=meta)\n",
        "\n",
        "    '''\n",
        "    --------------------------\n",
        "     ROI hooks\n",
        "    -----------------------------\n",
        "    '''\n",
        "\n",
        "    def read_roi(self, tile: RasterTile, row0: int, row1: int, col0: int, col1: int) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Returns a concrete numpy array (in RAM) for a ROI slice.\n",
        "        Keep ROIs reasonably sized (e.g., 512-2048 px).\n",
        "        \"\"\"\n",
        "        return np.array(tile.data[row0:row1, col0:col1], dtype=np.float32, copy=True)\n",
        "\n",
        "    # Backwards-compatible name (your earlier function name)\n",
        "    def extract_roi_pixels(self, tile: RasterTile, row_min: int, row_max: int, col_min: int, col_max: int) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Simple pixel ROI extraction (alias for read_roi).\n",
        "        \"\"\"\n",
        "        return self.read_roi(tile, row_min, row_max, col_min, col_max)\n",
        "\n",
        "    '''\n",
        "    --------------\n",
        "    Debug / provenance helpers\n",
        "    --------------\n",
        "    '''\n",
        "\n",
        "    def tile_provenance(self, tile_id: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Returns URLs + local paths so you can log them for reproducibility.\n",
        "        \"\"\"\n",
        "        if tile_id not in self.tiles:\n",
        "            raise KeyError(f\"Tile '{tile_id}' is not registered.\")\n",
        "        img_path, lbl_path = self._local_paths(tile_id)\n",
        "        spec = self.tiles[tile_id]\n",
        "        return {\n",
        "            \"tile_id\": tile_id,\n",
        "            \"img_url\": spec.img_url,\n",
        "            \"lbl_url\": spec.lbl_url,\n",
        "            \"local_img\": str(img_path),\n",
        "            \"local_lbl\": str(lbl_path),\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''def read_roi(self, tile: RasterTile, row0: int, row1: int, col0: int, col1: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Returns a concrete numpy array (in RAM) for a ROI slice.\n",
        "    Keep ROIs reasonably sized (e.g., 512-2048 px).\n",
        "    \"\"\"\n",
        "    roi = np.array(tile.data[row0:row1, col0:col1], dtype=np.float32, copy=True)\n",
        "    return roi\n",
        "'''"
      ],
      "metadata": {
        "id": "h68hEwivfF82"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE = \"https://pds-geosciences.wustl.edu/lro/lro-l-lola-3-rdr-v1/lrolol_1xxx/data/lola_gdr/polar/float_img\"\n",
        "\n",
        "tiles = [\n",
        "    LOLATileSpec(\n",
        "        tile_id=\"ldem_85n_20m_float\",\n",
        "        img_url=f\"{BASE}/ldem_85n_20m_float.img\",\n",
        "        lbl_url=f\"{BASE}/ldem_85n_20m_float.lbl\",\n",
        "    ),\n",
        "    LOLATileSpec(\n",
        "        tile_id=\"ldem_85s_20m_float\",\n",
        "        img_url=f\"{BASE}/ldem_85s_20m_float.img\",\n",
        "        lbl_url=f\"{BASE}/ldem_85s_20m_float.lbl\",\n",
        "    ),\n",
        "    LOLATileSpec(\n",
        "        tile_id=\"ldem_875n_20m_float\",\n",
        "        img_url=f\"{BASE}/ldem_875n_20m_float.img\",\n",
        "        lbl_url=f\"{BASE}/ldem_875n_20m_float.lbl\",\n",
        "    ),\n",
        "    LOLATileSpec(\n",
        "        tile_id=\"ldem_875s_20m_float\",\n",
        "        img_url=f\"{BASE}/ldem_875s_20m_float.img\",\n",
        "        lbl_url=f\"{BASE}/ldem_875s_20m_float.lbl\",\n",
        "    ),\n",
        "]\n",
        "\n",
        "dh = DataHandler(cache_dir=\"/content/endymion_cache/lola\")\n",
        "dh.register_tiles(tiles)\n",
        "\n",
        "\n",
        "tile = dh.load_tile(\"ldem_85s_20m_float\")\n",
        "print(tile.tile_id, tile.data.shape, tile.meta.sample_type, tile.meta.sample_bits)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2bETuhaWoRE",
        "outputId": "05e2d1e2-55a6-4fe2-9f52-194b2ce95904"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ldem_85s_20m_float (15168, 15168) PC_REAL 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tile = dh.load_tile(\"ldem_85s_20m_float\")\n",
        "roi_km = dh.read_roi(tile, 7000, 8024, 7000, 8024)  # 1024x1024 ROI\n"
      ],
      "metadata": {
        "id": "8_X_L1iIJ3cc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##standarise\n"
      ],
      "metadata": {
        "id": "_Qk_YHj_NVbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from typing import Literal\n",
        "\n",
        "@dataclass\n",
        "class TerrainTile:\n",
        "    \"\"\"\n",
        "    Standardised terrain tile for Endymion.\n",
        "    All values are in meters.\n",
        "    \"\"\"\n",
        "    data_m: np.ndarray\n",
        "    representation: Literal[\"height\", \"radius\"]\n",
        "    source_tile_id: str\n",
        "\n",
        "def standardise_lola(\n",
        "    tile: RasterTile,\n",
        "    *,\n",
        "    roi: np.ndarray | None = None,\n",
        "    representation: Literal[\"height\", \"radius\"] = \"height\",\n",
        ") -> TerrainTile:\n",
        "    \"\"\"\n",
        "    Standardise LOLA data to meters.\n",
        "\n",
        "    - tile.data is HEIGHT relative to reference sphere in km\n",
        "    - meta.offset is in km\n",
        "    - If roi is provided, standardise only that ROI\n",
        "    \"\"\"\n",
        "\n",
        "    height_km = roi if roi is not None else tile.data\n",
        "    height_km = np.array(height_km, dtype=np.float32, copy=False)\n",
        "\n",
        "    if representation == \"height\":\n",
        "        data_m = height_km * 1000.0\n",
        "\n",
        "    elif representation == \"radius\":\n",
        "        if tile.meta.offset is None:\n",
        "            raise ValueError(\"Cannot compute planetary radius: OFFSET missing in label.\")\n",
        "        data_m = (height_km + tile.meta.offset) * 1000.0\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown representation: {representation}\")\n",
        "\n",
        "    return TerrainTile(\n",
        "        data_m=data_m,\n",
        "        representation=representation,\n",
        "        source_tile_id=tile.tile_id,\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "1jXiN9stNWq_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ROI logic\n"
      ],
      "metadata": {
        "id": "GPlqXCiu-H2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Load tile as memmap (cheap)\n",
        "tile = dh.load_tile(\"ldem_85s_20m_float\")\n",
        "\n",
        "# Extract a small ROI (example: 1024x1024 window)\n",
        "roi_km = dh.read_roi(tile, 7000, 8024, 7000, 8024)\n",
        "\n",
        "print(\"ROI shape:\", roi_km.shape)\n",
        "print(\"ROI raw min/max (km):\", np.nanmin(roi_km), np.nanmax(roi_km))\n",
        "\n",
        "# Standardise the ROI only\n",
        "terrain = standardise_lola(tile, roi=roi_km, representation=\"height\")\n",
        "\n",
        "print(\"ROI height min/max (m):\",\n",
        "      np.nanmin(terrain.data_m),\n",
        "      np.nanmax(terrain.data_m))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZEROAwu-LYJ",
        "outputId": "de5e46dc-99b6-44e7-a668-66ac66fd280b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROI shape: (1024, 1024)\n",
            "ROI raw min/max (km): -2.8468773 1.7386577\n",
            "ROI height min/max (m): -2846.8774 1738.6577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##debugging"
      ],
      "metadata": {
        "id": "XxQrumWwh-zd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code below was suggested by Gemini AI\n",
        "\n",
        "# --- Debugging block to inspect the problematic label file ---\n",
        "tile_id_to_debug = \"ldem_85s_20m_float\"\n",
        "img_path, lbl_path = dh.ensure_downloaded(tile_id_to_debug, force=True)\n",
        "print(f\"\\n--- Content of {lbl_path} ---\")\n",
        "print(lbl_path.read_text(encoding=\"utf-8\", errors=\"ignore\"))\n",
        "print(f\"--- End of {lbl_path} content ---\\n\")\n",
        "# --- End Debugging block ---"
      ],
      "metadata": {
        "id": "f2XjuIOP8IOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(DataHandler)\n",
        "print(\"Has load_tile:\", hasattr(DataHandler, \"load_tile\"))\n",
        "print(\"Methods:\", [m for m in dir(DataHandler) if \"tile\" in m.lower()])\n"
      ],
      "metadata": {
        "id": "3CoBGPEdh-Ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tile = dh.load_tile(\"ldem_85s_20m_float\")\n",
        "\n",
        "terrain_h = standardise_lola(tile.data, tile.meta, representation=\"height\")\n",
        "print(np.nanmin(terrain_h.data_m), np.nanmax(terrain_h.data_m))\n",
        "\n",
        "terrain_r = standardise_lola(tile.data, tile.meta, representation=\"radius\")\n",
        "print(np.nanmin(terrain_r.data_m), np.nanmax(terrain_r.data_m))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHHsmCl2Te0Q",
        "outputId": "60c1c27f-5f5d-414f-fe9a-2f50008d7362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15168 15168 PC_REAL 32\n",
            "['UNCOMPRESSED_FILE.IMAGE.LINES', 'UNCOMPRESSED_FILE.IMAGE.LINE_SAMPLES']\n",
            "-5501.761 7027.1665\n",
            "1731898.4 1744427.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1731898400.0 1744427300.0 is way too big for “height”. Check for sanity"
      ],
      "metadata": {
        "id": "xot3-8Gh3dyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tile = dh.load_tile(\"ldem_85s_20m_float\", force_download=False)\n",
        "\n",
        "print(\"RAW dtype:\", tile.data.dtype)\n",
        "print(\"RAW min/max:\", np.nanmin(tile.data), np.nanmax(tile.data))\n",
        "print(\"OFFSET (km):\", tile.meta.offset)\n",
        "print(\"UNIT:\", tile.meta.raw.get(\"UNCOMPRESSED_FILE.IMAGE.UNIT\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo5-UPZ43k_D",
        "outputId": "711342ca-aa99-4f36-c48a-603edf31e09b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15168 15168 PC_REAL 32\n",
            "['UNCOMPRESSED_FILE.IMAGE.LINES', 'UNCOMPRESSED_FILE.IMAGE.LINE_SAMPLES']\n",
            "RAW dtype: float32\n",
            "RAW min/max: -5.5017614 7.0271664\n",
            "OFFSET (km): 1737.4\n",
            "UNIT: KILOMETER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, height checked. Now, verify the offset as is too high\n"
      ],
      "metadata": {
        "id": "m-KZCh1QCOvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"OFFSET raw:\", tile.meta.offset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VO2ZP-DCQ71",
        "outputId": "11edb321-42d4-4e2c-f582-298d0be750eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OFFSET raw: 1737.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "done"
      ],
      "metadata": {
        "id": "Sf-tn6ijEexu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OtXjqIWmCRdz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}